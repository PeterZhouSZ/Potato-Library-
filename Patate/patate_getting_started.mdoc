/*
 This Source Code Form is subject to the terms of the Mozilla Public
 License, v. 2.0. If a copy of the MPL was not distributed with this
 file, You can obtain one at http://mozilla.org/MPL/2.0/.
*/

/*!
  \page patate_getting_started_page Getting started

  \section getting_started_requirements_sec Requirements

  The only external library that is absolutely necessary to make Patates work is <a href="http://eigen.tuxfamily.org/" target="_blank"><b>Eigen</b></a>, the swiss army knife of linear algebra. Additional libraries might be required in specific instances, but only for advanced algorithms. We'll try to keep these dependencies to the minimum necessary, promised. Some examples will require additional libraries as well in an effort to keep them lean and legible.

  The PatateLib is also compatible with CUDA, so that you may run patates on the GPU, provided you own an NVidia graphics card. This is an efficient way to make patates available through CUDA-compatible languages such as Matlab or Python. Eigen can now be compiled by nvcc (NVIDIA CUDA Compiler Driver), see <a href="http://eigen.tuxfamily.org/dox-devel/TopicCUDA.html"  target="_blank">Eigen documentation</a> for more details.

  \section getting_started_download_sec Download

  The Patate library is currently under active development and some functionalities have already been implemented and thoroughly tested. If you want to get a taste of these prime features, use the latest package available here: https://gforge.inria.fr/projects/patate/.

  You may also want to monitor our efforts in developping the library, in which case you will want to access the development repository:
  \code
  git clone git://scm.gforge.inria.fr/patate/patate.git
  \endcode

  \section getting_started_installation_sec Installation

  The Patate lib is an header-only library. It could not be easier to install: the only thing you have to do is to include the header of the module you want to use in your code.
  Moreover, each patate|module is independent from the others, hence you may only use the header corresponding to the module you are interested in. For example:
	\code
	#include <Patate/grenaille.h>
	\endcode

  That said, the (quite heavy) use of templates in some modules may increase compilation times. Precompiled headers are recommended if this becomes a source of frustration. You will also have to pre-compile patates using nvcc if you want to use CUDA versions. This is explained in more details in related examples.

  If you want to see Patates in action, you will of course have to compile examples. And the same is true if you want to get the latest version of the documentation you are presently reading (well, not the exact same documentation, unless you've already compiled it, but then why are you reading this?). In both cases, have a look at the readme file, everything is explained there, no need to duplicate that here.

  \section getting_started_panorama_sec Overview

  You may already have had a look at the \link patate_overview_page list of available patates|modules. \endlink Here we'd like to add an important bit of information, if you don't mind.

  Even though each patate is independent, they all have the same simple structure: a "core" folder where you will find operators that rely on no data structure and work both with CUDA and C++; and an "algorithms" folder with methods that may interface with user-provided data structures, with optimized solutions in C++, CUDA or both.
  The rationale behind this separation is to provide two levels of complexity: core operators implement atomic scientific contributions that are agnostic of the host application; algorithms implement step-by-step procedures that will likely rely on core operators and/or structure traversal.
  For this reason, all operators become available whenever a patate/module is included; whereas each algorithm must be included independently.

  \section getting_started_first_step_sec First steps

  You're now ready to play with Patates! But where to start from?

  Say you're interested in the Grenaille module.
  You could take a look at its basic tutorial provided in its \ref grenaille_user_manual_page "user manual".
  It's very simple and... a bit boring. But at least you'll get the grip!

  Then you could play with other examples or start right away with yours!
  In the latter case, you may want to read carefully the \ref grenaille_user_manual_page "user manual", and check references in case of doubts.
  You might then wonder what the heck are these macro prefix useful for. I mean for instance this one:
  \code
	  MULTIARCH void function();
  \endcode

  It's important: it permits to use the same code for C++ and CUDA. It has no effect when the code is compiled with GCC or Clang, but it will force the compilation for both host and device architectures when compiling with nvcc. A similar macro system is provided for mathematical functions, to switch between STL and CUDA versions.

  We've already been a bit too deep for that "Getting Started" page, so we should end it up soon. One last thing: if you get stuck or have a problem/bug using patates, please send an email to patate-devel@lists.gforge.inria.fr for further assistance. Remember that the library is under development so we are pleased to get your feedback.
 */
