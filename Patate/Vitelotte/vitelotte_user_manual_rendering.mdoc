/*
 This Source Code Form is subject to the terms of the Mozilla Public
 License, v. 2.0. If a copy of the MPL was not distributed with this
 file, You can obtain one at http://mozilla.org/MPL/2.0/.
*/


namespace Vitelotte {

/*!
  \page vitelotte_user_manual_rendering_page Rendering

  \section vitelotte_user_manual_rendering_basics_sec Basic usage

  VGMeshRenderer is a simple renderer whose job is to emit the right OpenGL 3(+) calls to render a given mesh. It currently only support triangular meshes with linear or quadratic interpolation over each face. It also supports up to one singularity per triangle.

  Vitelotte is an header-only library, and its job is not to deal with OpenGL context creation and management. In practice, Vitelotte does not even include OpenGL headers as you may wish to use GLEW or a similar library that provides its own header. So, to use the renderer you need to do something like this:

  \code{.cpp}
  // Include some OpenGL header.
  #include <GL/glew.h>

  // Include Vitelotte's classes that depends on OpenGL. An OpenGL
  // header *must* have been included beforehand.
  #include <Patate/vitelotte_gl.h>
  \endcode

  Creating the renderer is straightforward:

  \code{.cpp}
  // As usual, VGMeshRenderer is parametrized by the Mesh class.
  VGMeshRenderer<Mesh> renderer;
  renderer.setResources(resources);
  \endcode

  Every VGMeshRenderer manages some OpenGL resources. They can be released by calling VGMeshRenderer::releaseGLResources().

  To upload data required for rendering to the GPU, just do

  \code{.cpp}
  renderer.updateBuffers(mesh);
  \endcode

  This must be called every time the mesh is modified. Note that the renderer does not keep reference to the mesh, so it can be deleted safely even if a renderer is setup to render it.

  Rendering can be done with the following methods:

  \code{.cpp}
  // Render the mesh given an Eigen::Matrix4f view matrix
  renderer.render(viewMatrix);

  // Render the mesh in wireframe
  renderer.renderWireframe(viewMatrix, viewportSize);
  \endcode

  Coordinates of the mesh's vertices are multiplied by the viewMatrix in the shader to produce the viewport coordinate. You should build the viewMatrix yourself to place the image correctly on the screen. Wireframe rendering require the viewport size to get the width of the lines right.

  Note that render() and renderWireframe should produce samples at the exact same depth. So to render a wireframe on top of a solid render, the easiest way is to set the depth test to GL_LEQUAL.


  \section vitelotte_user_manual_rendering_advanced_sec Advanced usage

  The renderer uses some global resources (shaders) that can be shared by several instances of VGMeshRenderer. By default, they are automatically created when needed (when you call a draw method). You can allocate them explicitly to share the resources among several renderers:

  \code{.cpp}
  # Can be called anytime
  VGMeshRendererResources resources;

  # Must be called with the correct OpenGL context active.
  resources.initialize();
  \endcode

  Then, you can pass the resources to an instance of VGMeshRenderer on construction or with VGMeshRenderer::setResources(). Resources can be released by calling VGMeshRendererResources::releaseGLResources() when the context is active.

  The input mesh can have an arbitrary number of dimensions and coefficients. By default, if the number of dimensions is smaller or equal to 4, the d fists coordinates are sent to OpenGL and missing ones are replaced by 0, except the last one which is set to 1. It works well with 2D and 3D meshes, and with 4D meshes where the 4th dimension is 1 (unless you know what you do). In other cases, you can pass a functor to VGMeshRenderer constructor that takes a VGMesh::Vector in parameter and returns an Eigen::Vector4f which is send to OpenGL.

  A similar mechanism is available for values. By default, single valued coefficient are rendered as grayscale, 2D values are rendered as grayscale + alpha, 3D values are rendered as RGB and 4D as RGBA.

  If you render with GL_FRAMEBUFFER_SRGB enabled to automatically convert linear fragment color to SRGB, the input mesh value should be linear. In order to help, you can enable SRGB to linear conversion in the solver with VGMeshRenderer::enableSrgbToLinearConversion(). Keep in mind though that for ideal results you should use the same color space for interpolation in OpenGL and in the solver (if you use the solver). Using a wrong interpolation may lead to visible artifacts (making the triangles visible). If you use a color space which is not supported by OpenGL, you need to customize the shaders.

  If you want to really customize the output, you may need to write your own shaders. You can setup your own OpenGL states and then call VGMeshRenderer::drawGeometry to setup the VAO and do the draw call. This function takes a combination of the NORMAL_TRIANGLES and the SINGULAR_TRIANGLES flags in parameter to determine if it should render normal triangles, singular triangles or both.

  We won't detail the way shaders works here. If you need to write custom shader, the easiest way is to start from Vitelotte's shaders (in `Patate/Vitelotte/Utils/VGMeshRendererShaders`) and modify it.

 */

}
